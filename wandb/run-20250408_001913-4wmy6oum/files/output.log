Epoch 1/10
[1m184/184[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m4s[0m 7ms/step - accuracy: 0.9294 - loss: 0.3182 - val_accuracy: 0.9612 - val_loss: 0.1350
Epoch 2/10
[1m184/184[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9623 - loss: 0.1357 - val_accuracy: 0.9612 - val_loss: 0.1286
Epoch 3/10
[1m184/184[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9630 - loss: 0.1302 - val_accuracy: 0.9612 - val_loss: 0.1143
Epoch 4/10
[1m184/184[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9577 - loss: 0.1272 - val_accuracy: 0.9612 - val_loss: 0.1080
Epoch 5/10
[1m184/184[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 5ms/step - accuracy: 0.9658 - loss: 0.1056 - val_accuracy: 0.9619 - val_loss: 0.1020
Epoch 6/10
[1m184/184[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 5ms/step - accuracy: 0.9627 - loss: 0.0989 - val_accuracy: 0.9612 - val_loss: 0.1025
Epoch 7/10
[1m184/184[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 5ms/step - accuracy: 0.9649 - loss: 0.0918 - val_accuracy: 0.9632 - val_loss: 0.0989
Epoch 8/10
[1m184/184[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 5ms/step - accuracy: 0.9613 - loss: 0.0859 - val_accuracy: 0.9619 - val_loss: 0.0990
Epoch 9/10
[1m184/184[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 5ms/step - accuracy: 0.9690 - loss: 0.0729 - val_accuracy: 0.9626 - val_loss: 0.0948
Epoch 10/10
[1m184/184[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 5ms/step - accuracy: 0.9681 - loss: 0.0763 - val_accuracy: 0.9592 - val_loss: 0.0964
Entraînement effectué sur GPU
[1m46/46[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 4ms/step - accuracy: 0.9562 - loss: 0.0961
Test Loss: 0.0964353084564209
Test Accuracy: 0.9591559171676636
[1m46/46[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 6ms/step

Rapport de classification:
              precision    recall  f1-score   support

         0.0       0.97      0.99      0.98      1412
         1.0       0.44      0.19      0.27        57

    accuracy                           0.96      1469
   macro avg       0.70      0.59      0.62      1469
weighted avg       0.95      0.96      0.95      1469

[1m46/46[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 2ms/step 
Accuracy:  0.9592
Precision: 0.4400
Recall:    0.1930
F1-score:  0.2683

Testing parameters: {'batch_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.01, 'lstm_units': 32}
Fold 1/3
C:\Users\jawus\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\keras\src\layers\rnn\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)
Epoch 1/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m3s[0m 7ms/step - accuracy: 0.9310 - loss: 0.2305 - val_accuracy: 0.9638 - val_loss: 0.1355
Epoch 2/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 5ms/step - accuracy: 0.9590 - loss: 0.1433 - val_accuracy: 0.9638 - val_loss: 0.1248
Epoch 3/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 5ms/step - accuracy: 0.9632 - loss: 0.1152 - val_accuracy: 0.9638 - val_loss: 0.1126
Epoch 4/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 5ms/step - accuracy: 0.9599 - loss: 0.1017 - val_accuracy: 0.9638 - val_loss: 0.1074
Epoch 5/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 5ms/step - accuracy: 0.9668 - loss: 0.0917 - val_accuracy: 0.9653 - val_loss: 0.0918
Epoch 6/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 5ms/step - accuracy: 0.9675 - loss: 0.0743 - val_accuracy: 0.9663 - val_loss: 0.0961
Epoch 7/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 5ms/step - accuracy: 0.9717 - loss: 0.0658 - val_accuracy: 0.9602 - val_loss: 0.1061
Epoch 8/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 5ms/step - accuracy: 0.9767 - loss: 0.0569 - val_accuracy: 0.9648 - val_loss: 0.1084
Fold 2/3
Epoch 1/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m3s[0m 7ms/step - accuracy: 0.9267 - loss: 0.2305 - val_accuracy: 0.9597 - val_loss: 0.1499
Epoch 2/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 5ms/step - accuracy: 0.9597 - loss: 0.1398 - val_accuracy: 0.9597 - val_loss: 0.1295
Epoch 3/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 5ms/step - accuracy: 0.9667 - loss: 0.0993 - val_accuracy: 0.9597 - val_loss: 0.1250
Epoch 4/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 5ms/step - accuracy: 0.9607 - loss: 0.1028 - val_accuracy: 0.9597 - val_loss: 0.1157
Epoch 5/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 5ms/step - accuracy: 0.9614 - loss: 0.0883 - val_accuracy: 0.9607 - val_loss: 0.1148
Epoch 6/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 5ms/step - accuracy: 0.9716 - loss: 0.0719 - val_accuracy: 0.9612 - val_loss: 0.1069
Epoch 7/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 5ms/step - accuracy: 0.9707 - loss: 0.0658 - val_accuracy: 0.9612 - val_loss: 0.1146
Epoch 8/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 5ms/step - accuracy: 0.9771 - loss: 0.0586 - val_accuracy: 0.9602 - val_loss: 0.1199
Epoch 9/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 5ms/step - accuracy: 0.9790 - loss: 0.0492 - val_accuracy: 0.9535 - val_loss: 0.1218
Fold 3/3
Epoch 1/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m3s[0m 7ms/step - accuracy: 0.9355 - loss: 0.2228 - val_accuracy: 0.9637 - val_loss: 0.1288
Epoch 2/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 5ms/step - accuracy: 0.9551 - loss: 0.1488 - val_accuracy: 0.9637 - val_loss: 0.1276
Epoch 3/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 5ms/step - accuracy: 0.9685 - loss: 0.1031 - val_accuracy: 0.9637 - val_loss: 0.1181
Epoch 4/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 5ms/step - accuracy: 0.9555 - loss: 0.1060 - val_accuracy: 0.9637 - val_loss: 0.1055
Epoch 5/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 5ms/step - accuracy: 0.9644 - loss: 0.0794 - val_accuracy: 0.9607 - val_loss: 0.1110
Epoch 6/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 5ms/step - accuracy: 0.9703 - loss: 0.0758 - val_accuracy: 0.9632 - val_loss: 0.1061
Epoch 7/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 5ms/step - accuracy: 0.9672 - loss: 0.0766 - val_accuracy: 0.9632 - val_loss: 0.1079
Mean validation accuracy: 0.9634
Mean validation loss: 0.1014

Testing parameters: {'batch_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.01, 'lstm_units': 50}
Fold 1/3
Epoch 1/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m3s[0m 8ms/step - accuracy: 0.9372 - loss: 0.2125 - val_accuracy: 0.9638 - val_loss: 0.1300
Epoch 2/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9548 - loss: 0.1408 - val_accuracy: 0.9638 - val_loss: 0.1131
Epoch 3/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9611 - loss: 0.1075 - val_accuracy: 0.9638 - val_loss: 0.1047
Epoch 4/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9618 - loss: 0.0978 - val_accuracy: 0.9638 - val_loss: 0.1109
Epoch 5/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9620 - loss: 0.0846 - val_accuracy: 0.9638 - val_loss: 0.0999
Epoch 6/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9728 - loss: 0.0679 - val_accuracy: 0.9689 - val_loss: 0.1129
Epoch 7/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9689 - loss: 0.0714 - val_accuracy: 0.9694 - val_loss: 0.1112
Epoch 8/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9770 - loss: 0.0529 - val_accuracy: 0.9617 - val_loss: 0.1102
Fold 2/3
Epoch 1/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m3s[0m 8ms/step - accuracy: 0.9284 - loss: 0.2375 - val_accuracy: 0.9597 - val_loss: 0.1357
Epoch 2/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9609 - loss: 0.1280 - val_accuracy: 0.9597 - val_loss: 0.1277
Epoch 3/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9660 - loss: 0.0983 - val_accuracy: 0.9597 - val_loss: 0.1114
Epoch 4/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9683 - loss: 0.0851 - val_accuracy: 0.9612 - val_loss: 0.1137
Epoch 5/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9689 - loss: 0.0739 - val_accuracy: 0.9617 - val_loss: 0.1122
Epoch 6/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9695 - loss: 0.0717 - val_accuracy: 0.9607 - val_loss: 0.1322
Fold 3/3
Epoch 1/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m3s[0m 8ms/step - accuracy: 0.9331 - loss: 0.2101 - val_accuracy: 0.9637 - val_loss: 0.1260
Epoch 2/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9616 - loss: 0.1257 - val_accuracy: 0.9637 - val_loss: 0.1221
Epoch 3/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9673 - loss: 0.0920 - val_accuracy: 0.9632 - val_loss: 0.1249
Epoch 4/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9632 - loss: 0.1043 - val_accuracy: 0.9637 - val_loss: 0.1095
Epoch 5/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9684 - loss: 0.0800 - val_accuracy: 0.9653 - val_loss: 0.1249
Epoch 6/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9758 - loss: 0.0736 - val_accuracy: 0.9571 - val_loss: 0.1145
Epoch 7/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9811 - loss: 0.0528 - val_accuracy: 0.9648 - val_loss: 0.1228
Mean validation accuracy: 0.9624
Mean validation loss: 0.1069

Testing parameters: {'batch_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.01, 'lstm_units': 64}
Fold 1/3
Epoch 1/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m3s[0m 8ms/step - accuracy: 0.9334 - loss: 0.2019 - val_accuracy: 0.9638 - val_loss: 0.1290
Epoch 2/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9603 - loss: 0.1379 - val_accuracy: 0.9638 - val_loss: 0.1223
Epoch 3/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9616 - loss: 0.1172 - val_accuracy: 0.9638 - val_loss: 0.1144
Epoch 4/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9622 - loss: 0.0987 - val_accuracy: 0.9663 - val_loss: 0.1126
Epoch 5/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9640 - loss: 0.0894 - val_accuracy: 0.9663 - val_loss: 0.1065
Epoch 6/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9667 - loss: 0.0761 - val_accuracy: 0.9658 - val_loss: 0.1138
Epoch 7/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9690 - loss: 0.0657 - val_accuracy: 0.9658 - val_loss: 0.1094
Epoch 8/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9770 - loss: 0.0545 - val_accuracy: 0.9612 - val_loss: 0.1063
Epoch 9/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9780 - loss: 0.0581 - val_accuracy: 0.9678 - val_loss: 0.1070
Epoch 10/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9847 - loss: 0.0403 - val_accuracy: 0.9622 - val_loss: 0.1233
Fold 2/3
Epoch 1/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m3s[0m 8ms/step - accuracy: 0.9459 - loss: 0.1964 - val_accuracy: 0.9592 - val_loss: 0.1357
Epoch 2/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9610 - loss: 0.1338 - val_accuracy: 0.9597 - val_loss: 0.1216
Epoch 3/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9647 - loss: 0.1004 - val_accuracy: 0.9597 - val_loss: 0.1218
Epoch 4/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9609 - loss: 0.1011 - val_accuracy: 0.9602 - val_loss: 0.1095
Epoch 5/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 7ms/step - accuracy: 0.9699 - loss: 0.0789 - val_accuracy: 0.9627 - val_loss: 0.1097
Epoch 6/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9724 - loss: 0.0600 - val_accuracy: 0.9597 - val_loss: 0.1098
Epoch 7/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 7ms/step - accuracy: 0.9689 - loss: 0.0712 - val_accuracy: 0.9617 - val_loss: 0.1244
Fold 3/3
Epoch 1/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m3s[0m 8ms/step - accuracy: 0.9308 - loss: 0.2404 - val_accuracy: 0.9637 - val_loss: 0.1489
Epoch 2/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9589 - loss: 0.1478 - val_accuracy: 0.9637 - val_loss: 0.1317
Epoch 3/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9658 - loss: 0.1052 - val_accuracy: 0.9637 - val_loss: 0.1092
Epoch 4/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9665 - loss: 0.0874 - val_accuracy: 0.9653 - val_loss: 0.1077
Epoch 5/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9697 - loss: 0.0751 - val_accuracy: 0.9627 - val_loss: 0.1181
Epoch 6/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9684 - loss: 0.0747 - val_accuracy: 0.9597 - val_loss: 0.1232
Epoch 7/10
[1m123/123[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9748 - loss: 0.0708 - val_accuracy: 0.9602 - val_loss: 0.1195
Mean validation accuracy: 0.9622
Mean validation loss: 0.1078

Testing parameters: {'batch_size': 50, 'dropout_rate': 0.2, 'learning_rate': 0.01, 'lstm_units': 32}
Fold 1/3
Epoch 1/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 9ms/step - accuracy: 0.9229 - loss: 0.2523 - val_accuracy: 0.9638 - val_loss: 0.1331
Epoch 2/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 6ms/step - accuracy: 0.9622 - loss: 0.1378 - val_accuracy: 0.9571 - val_loss: 0.1272
Epoch 3/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 6ms/step - accuracy: 0.9616 - loss: 0.1191 - val_accuracy: 0.9638 - val_loss: 0.1143
Epoch 4/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 6ms/step - accuracy: 0.9593 - loss: 0.1060 - val_accuracy: 0.9638 - val_loss: 0.1042
Epoch 5/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 6ms/step - accuracy: 0.9638 - loss: 0.0864 - val_accuracy: 0.9684 - val_loss: 0.0923
Epoch 6/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 6ms/step - accuracy: 0.9704 - loss: 0.0753 - val_accuracy: 0.9627 - val_loss: 0.1000
Epoch 7/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 6ms/step - accuracy: 0.9741 - loss: 0.0749 - val_accuracy: 0.9658 - val_loss: 0.1028
Epoch 8/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 6ms/step - accuracy: 0.9776 - loss: 0.0599 - val_accuracy: 0.9643 - val_loss: 0.1061
Fold 2/3
Epoch 1/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 9ms/step - accuracy: 0.9320 - loss: 0.2344 - val_accuracy: 0.9597 - val_loss: 0.1405
Epoch 2/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 6ms/step - accuracy: 0.9612 - loss: 0.1345 - val_accuracy: 0.9597 - val_loss: 0.1237
Epoch 3/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 6ms/step - accuracy: 0.9636 - loss: 0.1047 - val_accuracy: 0.9597 - val_loss: 0.1158
Epoch 4/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 6ms/step - accuracy: 0.9643 - loss: 0.0958 - val_accuracy: 0.9597 - val_loss: 0.1146
Epoch 5/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 6ms/step - accuracy: 0.9664 - loss: 0.0783 - val_accuracy: 0.9561 - val_loss: 0.1170
Epoch 6/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 6ms/step - accuracy: 0.9684 - loss: 0.0738 - val_accuracy: 0.9622 - val_loss: 0.1237
Epoch 7/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 6ms/step - accuracy: 0.9707 - loss: 0.0689 - val_accuracy: 0.9587 - val_loss: 0.1228
Fold 3/3
Epoch 1/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m3s[0m 9ms/step - accuracy: 0.9284 - loss: 0.2548 - val_accuracy: 0.9637 - val_loss: 0.1308
Epoch 2/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 6ms/step - accuracy: 0.9645 - loss: 0.1288 - val_accuracy: 0.9637 - val_loss: 0.1288
Epoch 3/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 6ms/step - accuracy: 0.9638 - loss: 0.1120 - val_accuracy: 0.9637 - val_loss: 0.1154
Epoch 4/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9635 - loss: 0.1057 - val_accuracy: 0.9637 - val_loss: 0.1129
Epoch 5/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 6ms/step - accuracy: 0.9661 - loss: 0.0885 - val_accuracy: 0.9612 - val_loss: 0.1167
Epoch 6/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 6ms/step - accuracy: 0.9663 - loss: 0.0770 - val_accuracy: 0.9642 - val_loss: 0.1185
Epoch 7/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 6ms/step - accuracy: 0.9677 - loss: 0.0746 - val_accuracy: 0.9530 - val_loss: 0.1122
Epoch 8/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 6ms/step - accuracy: 0.9779 - loss: 0.0577 - val_accuracy: 0.9617 - val_loss: 0.1060
Epoch 9/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 6ms/step - accuracy: 0.9800 - loss: 0.0457 - val_accuracy: 0.9688 - val_loss: 0.1004
Epoch 10/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 7ms/step - accuracy: 0.9778 - loss: 0.0427 - val_accuracy: 0.9566 - val_loss: 0.1175
Mean validation accuracy: 0.9656
Mean validation loss: 0.1024

Testing parameters: {'batch_size': 50, 'dropout_rate': 0.2, 'learning_rate': 0.01, 'lstm_units': 50}
Fold 1/3
Epoch 1/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m3s[0m 10ms/step - accuracy: 0.9387 - loss: 0.2140 - val_accuracy: 0.9638 - val_loss: 0.1340
Epoch 2/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9620 - loss: 0.1332 - val_accuracy: 0.9638 - val_loss: 0.1194
Epoch 3/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 6ms/step - accuracy: 0.9643 - loss: 0.1072 - val_accuracy: 0.9638 - val_loss: 0.1247
Epoch 4/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 7ms/step - accuracy: 0.9641 - loss: 0.1048 - val_accuracy: 0.9632 - val_loss: 0.1099
Epoch 5/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 7ms/step - accuracy: 0.9662 - loss: 0.0822 - val_accuracy: 0.9581 - val_loss: 0.1163
Epoch 6/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 7ms/step - accuracy: 0.9671 - loss: 0.0796 - val_accuracy: 0.9673 - val_loss: 0.1220
Epoch 7/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 7ms/step - accuracy: 0.9734 - loss: 0.0686 - val_accuracy: 0.9612 - val_loss: 0.1273
Fold 2/3
Epoch 1/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m3s[0m 10ms/step - accuracy: 0.9331 - loss: 0.2154 - val_accuracy: 0.9592 - val_loss: 0.1358
Epoch 2/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 7ms/step - accuracy: 0.9654 - loss: 0.1213 - val_accuracy: 0.9597 - val_loss: 0.1241
Epoch 3/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 7ms/step - accuracy: 0.9609 - loss: 0.1125 - val_accuracy: 0.9597 - val_loss: 0.1206
Epoch 4/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 7ms/step - accuracy: 0.9663 - loss: 0.0901 - val_accuracy: 0.9597 - val_loss: 0.1086
Epoch 5/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 9ms/step - accuracy: 0.9680 - loss: 0.0729 - val_accuracy: 0.9622 - val_loss: 0.1161
Epoch 6/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 8ms/step - accuracy: 0.9740 - loss: 0.0695 - val_accuracy: 0.9556 - val_loss: 0.1254
Epoch 7/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 9ms/step - accuracy: 0.9763 - loss: 0.0568 - val_accuracy: 0.9561 - val_loss: 0.1178
Fold 3/3
Epoch 1/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m3s[0m 10ms/step - accuracy: 0.9297 - loss: 0.2346 - val_accuracy: 0.9612 - val_loss: 0.1380
Epoch 2/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 7ms/step - accuracy: 0.9577 - loss: 0.1412 - val_accuracy: 0.9637 - val_loss: 0.1324
Epoch 3/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 7ms/step - accuracy: 0.9636 - loss: 0.1144 - val_accuracy: 0.9637 - val_loss: 0.1251
Epoch 4/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 7ms/step - accuracy: 0.9630 - loss: 0.1137 - val_accuracy: 0.9637 - val_loss: 0.1420
Epoch 5/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 7ms/step - accuracy: 0.9619 - loss: 0.1006 - val_accuracy: 0.9653 - val_loss: 0.1255
Epoch 6/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 8ms/step - accuracy: 0.9643 - loss: 0.0902 - val_accuracy: 0.9607 - val_loss: 0.1305
Mean validation accuracy: 0.9622
Mean validation loss: 0.1145

Testing parameters: {'batch_size': 50, 'dropout_rate': 0.2, 'learning_rate': 0.01, 'lstm_units': 64}
Fold 1/3
Epoch 1/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m3s[0m 10ms/step - accuracy: 0.9050 - loss: 0.2318 - val_accuracy: 0.9638 - val_loss: 0.1334
Epoch 2/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 7ms/step - accuracy: 0.9628 - loss: 0.1209 - val_accuracy: 0.9638 - val_loss: 0.1216
Epoch 3/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 7ms/step - accuracy: 0.9604 - loss: 0.1090 - val_accuracy: 0.9622 - val_loss: 0.1200
Epoch 4/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 7ms/step - accuracy: 0.9564 - loss: 0.1036 - val_accuracy: 0.9622 - val_loss: 0.1083
Epoch 5/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 7ms/step - accuracy: 0.9622 - loss: 0.0883 - val_accuracy: 0.9612 - val_loss: 0.1137
Epoch 6/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 8ms/step - accuracy: 0.9703 - loss: 0.0733 - val_accuracy: 0.9638 - val_loss: 0.1194
Epoch 7/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 8ms/step - accuracy: 0.9699 - loss: 0.0737 - val_accuracy: 0.9617 - val_loss: 0.1157
Fold 2/3
Epoch 1/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m3s[0m 10ms/step - accuracy: 0.9146 - loss: 0.2330 - val_accuracy: 0.9597 - val_loss: 0.1344
Epoch 2/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 7ms/step - accuracy: 0.9585 - loss: 0.1306 - val_accuracy: 0.9597 - val_loss: 0.1250
Epoch 3/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 7ms/step - accuracy: 0.9667 - loss: 0.0985 - val_accuracy: 0.9597 - val_loss: 0.1117
Epoch 4/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 8ms/step - accuracy: 0.9602 - loss: 0.0961 - val_accuracy: 0.9602 - val_loss: 0.1228
Epoch 5/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 8ms/step - accuracy: 0.9630 - loss: 0.0905 - val_accuracy: 0.9592 - val_loss: 0.1091
Epoch 6/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 8ms/step - accuracy: 0.9678 - loss: 0.0717 - val_accuracy: 0.9571 - val_loss: 0.1204
Epoch 7/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 8ms/step - accuracy: 0.9752 - loss: 0.0628 - val_accuracy: 0.9617 - val_loss: 0.1018
Epoch 8/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 8ms/step - accuracy: 0.9808 - loss: 0.0574 - val_accuracy: 0.9587 - val_loss: 0.1071
Epoch 9/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 8ms/step - accuracy: 0.9795 - loss: 0.0519 - val_accuracy: 0.9648 - val_loss: 0.1136
Epoch 10/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 8ms/step - accuracy: 0.9827 - loss: 0.0411 - val_accuracy: 0.9602 - val_loss: 0.1179
Fold 3/3
Epoch 1/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m3s[0m 11ms/step - accuracy: 0.9277 - loss: 0.2338 - val_accuracy: 0.9637 - val_loss: 0.1434
Epoch 2/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 8ms/step - accuracy: 0.9616 - loss: 0.1406 - val_accuracy: 0.9637 - val_loss: 0.1301
Epoch 3/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 10ms/step - accuracy: 0.9588 - loss: 0.1289 - val_accuracy: 0.9637 - val_loss: 0.1283
Epoch 4/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 9ms/step - accuracy: 0.9611 - loss: 0.1092 - val_accuracy: 0.9637 - val_loss: 0.1214
Epoch 5/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 9ms/step - accuracy: 0.9624 - loss: 0.0961 - val_accuracy: 0.9581 - val_loss: 0.1218
Epoch 6/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 10ms/step - accuracy: 0.9652 - loss: 0.0795 - val_accuracy: 0.9658 - val_loss: 0.1156
Epoch 7/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 8ms/step - accuracy: 0.9733 - loss: 0.0653 - val_accuracy: 0.9535 - val_loss: 0.1256
Epoch 8/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 8ms/step - accuracy: 0.9713 - loss: 0.0732 - val_accuracy: 0.9612 - val_loss: 0.1202
Epoch 9/10
[1m79/79[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 8ms/step - accuracy: 0.9834 - loss: 0.0469 - val_accuracy: 0.9632 - val_loss: 0.1168
Mean validation accuracy: 0.9632
Mean validation loss: 0.1086

Résultats d'optimisation des hyperparamètres:
   batch_size  dropout_rate  learning_rate  lstm_units  mean_val_accuracy  \
3          50           0.2           0.01          32           0.965623
0          32           0.2           0.01          32           0.963411
5          50           0.2           0.01          64           0.963241
1          32           0.2           0.01          50           0.962390
2          32           0.2           0.01          64           0.962220
4          50           0.2           0.01          50           0.962219

   mean_val_loss  std_val_accuracy
3       0.102397          0.004212
0       0.101420          0.001683
5       0.108556          0.001809
1       0.106932          0.001921
2       0.107827          0.002197
4       0.114524          0.001812

Meilleurs hyperparamètres: {'batch_size': np.float64(50.0), 'dropout_rate': np.float64(0.2), 'learning_rate': np.float64(0.01), 'lstm_units': np.float64(32.0), 'mean_val_accuracy': np.float64(0.9656234184900919), 'mean_val_loss': np.float64(0.10239703953266144), 'std_val_accuracy': np.float64(0.004212221837874388)}
C:\Users\jawus\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\keras\src\layers\rnn\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)
[34m[1mwandb[0m: [32m[41mERROR[0m The nbformat package was not found. It is required to save notebook history.
